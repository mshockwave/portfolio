<!doctype html><html lang=en><head><meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Calculate Throughput with LLVM's Scheduling Model&nbsp;|&nbsp;Min Hsu's Homepage</title>
<meta name=title content="Calculate Throughput with LLVM's Scheduling Model"><meta name=description content="Compiler, uArch, and a little bit of...jigsaw puzzle?"><meta name=keywords content="llvm,compiler-instruction-scheduling,performance,"><meta name=author content="Min-Yih Hsu"><meta property="og:title" content="Calculate Throughput with LLVM's Scheduling Model"><meta property="og:description" content="Compiler, uArch, and a little bit of...jigsaw puzzle?"><meta property="og:type" content="article"><meta property="og:url" content="https://myhsu.xyz/llvm-sched-interval-throughput/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-03-23T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-23T00:00:00+00:00"><meta property="og:site_name" content="Min Hsu's Homepage"><meta name=twitter:card content="summary"><meta name=twitter:title content="Calculate Throughput with LLVM's Scheduling Model"><meta name=twitter:description content="Compiler, uArch, and a little bit of...jigsaw puzzle?"><meta itemprop=name content="Calculate Throughput with LLVM's Scheduling Model"><meta itemprop=description content="Compiler, uArch, and a little bit of...jigsaw puzzle?"><meta itemprop=datePublished content="2025-03-23T00:00:00+00:00"><meta itemprop=dateModified content="2025-03-23T00:00:00+00:00"><meta itemprop=wordCount content="2409"><meta itemprop=keywords content="llvm,compiler-instruction-scheduling,performance,"><meta name=referrer content="no-referrer-when-downgrade"><link href=/simple.min.css rel=stylesheet><link href=/style.min.css rel=stylesheet></head><body><header><nav><a href=/>Home</a>
<a href=/publications/>Publications</a>
<a href=/blog/>Blog</a>
<a href=https://github.com/mshockwave>GitHub</a>
<a href=https://www.linkedin.com/in/bekketmcclane/>LinkedIn</a>
<a href=/index.xml><svg xmlns="http://www.w3.org/2000/svg" class="icon" viewBox="0 0 448 512"><path d="M0 64C0 46.3 14.3 32 32 32c229.8.0 416 186.2 416 416 0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96 14.3 96 0 81.7.0 64zM0 416a64 64 0 11128 0A64 64 0 110 416zM32 160c159.1.0 288 128.9 288 288 0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224-17.7.0-32-14.3-32-32s14.3-32 32-32z"/></svg>
RSS</a></nav><h1>Calculate Throughput with LLVM's Scheduling Model</h1><p>Compiler, uArch, and a little bit of...jigsaw puzzle?</p></header><main><p><i><time datetime=2025-03-23 pubdate>2025-03-23</time></i></p><content><p>From Cambridge Dictionary:</p><blockquote><p><strong>Throughput</strong> /ÀàŒ∏ruÀê.p ät/ (noun)</p><ul><li>an amount of work done in a particular period of time.</li></ul></blockquote><p>In architecture-level performance analysis, throughput is usually measured by IPC &ndash; Instruction Per Cycle. The inverse of this property, namely, inverse or reciprocal throughput, is also commonly used to describe the performance characteristics of a sinlge instruction.
It&rsquo;s not the time an instruction spends on to finish from start to end &ndash; that is <em>latency</em> &ndash; but more closed to the amount of time it takes to finish a bunch of instructions amortized by their degree of (instruction-level) <em>parallelism</em>.</p><p>LLVM&rsquo;s scheduling model &ndash; which we&rsquo;d covered in <a href=/llvm-sched-model-1>several posts</a> previously &ndash; is a huge database describing the performance characteristics of instructions in a specific processor. While it specifies the instruction latency, a scheduling model does not spells out the inverse throughput of each instruction. We are, however, able to derive this property from other metrics in the model, and this short post is dedicated to show you how to do it.</p><h4 id=scheduling-model-in-a-nutshell>Scheduling model in a nutshell</h4><p>A scheduling model in LLVM describes an instruction with three primary properties:</p><ol><li>Latency</li><li>Hardware resources it uses</li><li>Number of cycles it &ldquo;holds&rdquo; on each of these hardware resources</li></ol><p>A hardware resource can be thought as an <em>execution pipe</em> in a superscalar processor. Let&rsquo;s say we have an instruction <code>BLAH</code> which uses three pipes, Pipe0 to Pipe2 (<code>P0</code> ~ <code>P2</code>), during its execution. We can describe the number of cycles it holds on each of these three pipes with a pair of numbers: <code>AcquireAtCycle</code> and <code>ReleaseAtCycle</code>.</p><p><code>AcquireAtCycle</code> equals to the cycle where <code>BLAH</code> grabs a certain pipe and start working, <strong>relative</strong> to the cycle when instruction was issued, this value is usually zero, meaning this instruction starts using this resource as soon as it was issued &ndash; we&rsquo;ll talk about the scenario where it&rsquo;s NOT (spoiler alert: it has more fun), but right now let&rsquo;s just assume it&rsquo;s always zero; similarly, <code>ReleaseAtCycle</code> is the cycle where <code>BLAH</code> releases this pipe for other instructions to use, also relative to the cycle instruction was issued.</p><p>To give a more concrete example, let&rsquo;s say <code>BLAH</code> has the following <code>AcquireAtCycle</code> and <code>ReleaseAtCycle</code> for each of the pipes it uses:</p><table><thead><tr><th style=text-align:center></th><th style=text-align:center>AcquireAtCycle</th><th style=text-align:center>ReleaseAtCycle</th></tr></thead><tbody><tr><td style=text-align:center>P0</td><td style=text-align:center>0</td><td style=text-align:center>1</td></tr><tr><td style=text-align:center>P1</td><td style=text-align:center>0</td><td style=text-align:center>3</td></tr><tr><td style=text-align:center>P2</td><td style=text-align:center>0</td><td style=text-align:center>2</td></tr></tbody></table><p>We can put it on the timeline like this:</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-basic.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-basic.light.drawio.svg></picture></div><p>As you probably also noticed, <code>ReleaseAtCycle</code> is the cycle where a resource had <em>already</em> been released, which means that the time an instruction spends on a certain resource is an interval closed on the left and opened on the right:</p><p><code>[AcquireAtCycle, ReleaseAtCycle)</code></p><p>Making it easier to calculate the number of cycles in this interval by subtracting these two fields.</p><p>If we have two <code>BLAH</code> issued back-to-back:</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-basic2.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-basic2.light.drawio.svg></picture></div><p>An instruction is allowed to be issued only if <em>all</em> the hardware resources it needs are available. That&rsquo;s why the second instruction is issued on cycle 3 &ndash; issued at any earlier cycles would result in at least one resource being unavailable.</p><p>It is also worth noting that <code>AcquireAtCycle</code> / <code>ReleaseAtCycle</code> only accounts for the time an instruction <strong>exclusively</strong> holds on a single resource<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. When we say <code>BLAH</code> holds <code>P1</code> for 3 cycles according to the table above, <code>BLAH</code> might take longer than 3 cycles to completely finish the entire instruction &ndash; 3 cycles are just the duration it blocks every other instructions from using <code>P1</code>. After these 3 cycles <code>BLAH</code> might keep running until it finishes. And the time it takes to finish from start to end, is <strong>latency</strong>.</p><p>So assuming <code>BLAH</code> has a latency of 5 cycles, this is what it looks like when we zoom into <code>P1</code>:</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-ilp.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-ilp.light.drawio.svg></picture></div><p>Each row is an instruction in this diagram. Boxes with solid edges are the duration <code>BLAH</code> holds onto <code>P1</code>; dashed boxes mark the extra time <code>BLAH</code> spends on to actually finish. As you can see, the combined duration of solid and dashed boxes is equal to the latency of <code>BLAH</code> &ndash; 5 cycles.</p><p>Pretty straightforward, right? Now let&rsquo;s see how to calculate the (inverse) throughput in this scenario.</p><h4 id=basic-throughput-calculation>Basic throughput calculation</h4><p>Earlier we mentioned that inverse throughput is the time to execute a group of instructions amortized by their degree of instruction-level parallelism. On the hind sight, it sounds like we need to know how long it takes to run <code>N</code> instructions, and divided by the number of instructions on the fly in this duration &ndash; which are both something compiler cannot easily figure out statically.</p><p>But in reality, it&rsquo;s actually pretty easy to know the throughput with <code>ReleaseAtCycle</code>. Recall the diagram we just saw, but increase the number of instructions on the fly:</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-ilp2.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-ilp2.light.drawio.svg></picture></div><p>The total number of cycles it takes to finish these instructions is <code>ReleaseAtCycle x N + (Latency - ReleaseAtCycle)</code> (or <code>ReleaseAtCycle x (N - 1) + Latency</code> if you prefer), where <code>N</code> is the number of instructions we see here, which means we&rsquo;re going to spend <code>3 x 4 + (5 - 3)</code>, 14 cycles in total.</p><p>If we increase the value of <code>N</code> to, let&rsquo;s say <em>infinity</em>, then <code>(Latency - ReleaseAtCycle)</code> &ndash; which is a constant &ndash; will actually become really insignificant! What actually dominates the total number of cycles becomes <code>ReleaseAtCycle x N</code>.
So eventually, the inverse throughput with regards to this particular resource, <code>P1</code>, equals to <code>ReleaseAtCycle x N / N = ReleaseAtCycle</code>.</p><p>But hold on a second what about <em>other</em> resources like <code>P0</code> and <code>P2</code>? Applying the same diagram on these two pipes and you&rsquo;ll find out their total time to finish <code>N</code> instructions are shorter than 14 cycles imposed by <code>P1</code>. Meaning <code>P1</code>&rsquo;s total time dominates the inverse throughput of this instruction, making other two&rsquo;s insignificant (even they finish ealier, they have to wait for <code>P1</code>). And this is caused by the fact that <code>P1</code> has the <em>largest</em> <code>ReleaseAtCycle</code>, which finally leads to a neat formula for calculating inverse throughput of the <strong>entire instruction</strong>:</p><pre tabindex=0><code>max(ReleaseAtCycle_0, ReleaseAtCycle_1, ..., ReleaseAtCycle_N)</code></pre><p>or</p><pre tabindex=0><code>max(ReleaseAtCycles)</code></pre><p>This formula is also what <code>MCSchedModel::getReciprocalThroughput</code> <a href=https://github.com/llvm/llvm-project/blob/616737c386776b0cfbda888a4d52e6036ccf1af8/llvm/lib/MC/MCSchedule.cpp#L107>uses</a> to calculate the inverse throughput of an instruction &ndash; modulo some differences like accounting for number of units of a resource<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, which we assume it to be one in our discussions.</p><p>Now, I won&rsquo;t spend hours wrestling with grammar, go all the way around to <strong>just</strong> write a blog post about something you can look up from code in a couple of minutes &ndash; the things we&rsquo;ve discussed so far are just a prelude to the <strong><em>fun</em></strong> part:</p><p>How to calculate throughput when <code>AcquireAtCycle</code> is not zero.</p><h4 id=calculating-throughput-with-resource-segments>Calculating throughput with resource segments</h4><p>Let&rsquo;s look at another instruction, <code>BLOB</code>, with the following <code>AcquireAtCycle</code> and <code>ReleaseAtCycle</code> numbers on <code>P0</code> ~ <code>P2</code>:</p><table><thead><tr><th style=text-align:center></th><th style=text-align:center>AcquireAtCycle</th><th style=text-align:center>ReleaseAtCycle</th></tr></thead><tbody><tr><td style=text-align:center>P0</td><td style=text-align:center>0</td><td style=text-align:center>2</td></tr><tr><td style=text-align:center>P1</td><td style=text-align:center>2</td><td style=text-align:center>5</td></tr><tr><td style=text-align:center>P2</td><td style=text-align:center>1</td><td style=text-align:center>3</td></tr></tbody></table><p>When <code>AcquireAtCycle</code> is greater than zero, the instruction will not seize this resource right after being issued, but until another <code>AcquireAtCycle</code> cycles later. Which means the duration <code>BLOB</code> holds on each resources &ndash; also known as <strong>resource segments</strong> &ndash; now looks like:</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-segment.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-segment.light.drawio.svg></picture></div><p>The biggest implication of having non-zero <code>AcquireAtCycle</code> is that the <em>second</em> <code>BLOB</code> instruction that comes after will be issued and arranged like this:</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-segment2.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-segment2.light.drawio.svg></picture></div><p>Meaning, we can issue the second <code>BLOB</code> as early as cycle 3 &ndash; as opposed to cycle 5 when all of the <code>AcquireAtCycle</code> are zero. It&rsquo;s safe to &ldquo;run ahead&rdquo; and issue early because although <code>BLOB</code> seizes <code>P0</code> right away, there is a slack before it tries to acquire <code>P1</code> and <code>P2</code> a few cycles later.</p><p>This is how an instructions with resource segments is scheduled. Now, how do we calculate its inverse throughput?</p><p>There are several insights we learned about calculating inverse throughput of non-resource-segment instructions from the previous section:</p><ul><li>Compared to <code>ReleaseAtCycle</code> (and <code>AcquireAtCycle</code>), latency doesn&rsquo;t really matter &ndash; it&rsquo;ll eventually be a single constant appended at the end of the formula that can be ignored when number of instructions (i.e. <code>N</code>) is approaching infinity</li><li>The whole calculation can be simplified to dividing the cycle at which the last instruction releases the last resource &ndash; or the <em>right-most</em> cycle, which is cycle 7 in the last diagram &ndash; by <code>N</code>. For non-resource-segment instructions, the right-most cycle is always <code>max(ReleaseAtCycles) x N</code></li></ul><p>So our task can really boil down to finding the right-most cycle here.
Looking at the last diagram, we might considering using <code>max(ReleaseAtCycles) x N</code> as the right-most cycle for instructions with resource segments here again.</p><p>Because first, the resource with <code>max(ReleaseAtCycles)</code> &ndash; <code>P1</code> in this case &ndash; will always be the resource where right-most cycle happens. Now the question would be the quantity of this right-most cycle: <em>Intuitively</em>, resource with <code>max(ReleaseAtCycles)</code> will always be the one that concatenates with its counterpart in the next instruction, back to back, without any &ldquo;gap&rdquo; in between. So the quantity of right-most cycle can be easily calculated as <code>max(ReleaseAtCycles) x N</code>.</p><p>As you might have noticed, having no gap is an important prerequisite here, otherwise if there is a gap, it will becomes part of the <em>recurring</em> factor. Namely, the right-most cycle will be something like <code>(max(ReleaseAtCycles) + C) x N</code> where <code>C</code> is a constant factor of gap.</p><p>But is it always the case for resources with <code>max(ReleaseAtCycles)</code> to have no gaps in between?</p><p>Sadly, here is a counter example:</p><table><thead><tr><th style=text-align:center></th><th style=text-align:center>AcquireAtCycle</th><th style=text-align:center>ReleaseAtCycle</th></tr></thead><tbody><tr><td style=text-align:center>P0</td><td style=text-align:center>0</td><td style=text-align:center>2</td></tr><tr><td style=text-align:center>P1</td><td style=text-align:center>4</td><td style=text-align:center>5</td></tr><tr><td style=text-align:center>P2</td><td style=text-align:center>1</td><td style=text-align:center>4</td></tr></tbody></table><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-segment3.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-segment3.light.drawio.svg></picture></div><p>There is still a silver lining in this though: regardless of gap, the resource with <code>max(ReleaseAtCycles)</code> is still the resource where right-most cycle happens &ndash; as we can observe from this counter example as well. So if we can figure out <code>C</code> &ndash; the constant factor of gap &ndash; then we still can calculate the inverse throughput in terms of <code>max(ReleaseAtCycles)</code>.</p><p>For that, let&rsquo;s play a liiiitle bit of jigsaw puzzle.</p><p>Let&rsquo;s step back a little bit and think about how we placed our second instruction in the first place which eventually led to the last diagram: starting from cycle 0, we effectively &ldquo;shift&rdquo; the second instruction right by <code>M</code> cycles, so far beyond that there is no overlap between the two instructions.</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-segment4.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-segment4.light.drawio.svg></picture></div><p>Then, we shift the second instruction left by <code>D</code> until one of the resources <em>touches</em> its counterpart in the first instruction.</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-segment4-2.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-segment4-2.light.drawio.svg></picture></div><p>To simplify, we can set <code>M</code>, the right shift amount, to be <code>max(ReleaseAtCycles)</code> (<code>R_max</code> in the diagram below):</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-segment4-3.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-segment4-3.light.drawio.svg></picture></div><p>With <code>M = max(ReleaseAtCycles)</code>, the distance between the right edges of both <code>P1</code> boxes becomes <code>max(ReleaseAtCycles) - D</code> after we shift the second instruction left by <code>D</code>:</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-segment4-4.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-segment4-4.light.drawio.svg></picture></div><p>This distance, <code>max(ReleaseAtCycles) - D</code>, is especially important because it&rsquo;s the recurring factor <code>max(ReleaseAtCycles) + C</code> mentioned earlier (i.e. <code>C = -D</code>). In other words, the right-most cycle we&rsquo;ve been looking for is equal to <code>(max(ReleaseAtCycles) - D) x N</code> when <code>N</code> is sufficiently big:</p><div style=text-align:center><picture><source srcset=/images/llvm-sched-interval-throughput-segment4-5.dark.drawio.svg media="(prefers-color-scheme: dark)"><img src=/images/llvm-sched-interval-throughput-segment4-5.light.drawio.svg></picture></div><p>So now we only have one thing left: finding the value of <code>D</code>.</p><p>During the left shifting, if we look at each hardware resource in the second instruction <em>individually</em>, each of them needs to move a different distance before touching their counterpart in the first instruction. Using the last setup as example, <code>P0</code> needs to shift 3 cycles left, 4 cycles for <code>P1</code>, and 2 cycles for <code>P2</code>. The value of <code>D</code> would be the minimum among them (i.e. <code>D = 2</code>). Furthermore, the individual shifting amount can be expressed as</p><pre tabindex=0><code>(AcquireAtCycle + M) - ReleaseAtCycle</code></pre><p>Because <code>AcquireAtCycle + M</code> is effectively the &ldquo;new&rdquo; <code>AcquireAtCycle</code> after we shift it right by <code>M</code>, and subtracting it with <code>ReleaseAtCycle</code> (of the first instruction), would give you the distance to close up.</p><p>Therefore:</p><pre tabindex=0><code>D = min((AcquireAtCycle_i + M) - ReleaseAtCycle_i), ‚àÄ i = P0 ~ P2
  = min(M - (ReleaseAtCycle_i - AcquireAtCycle_i))</code></pre><p>Because <code>M</code> is constant, to get the minimum of <code>M - (ReleaseAtCycle_i - AcquireAtCycle_i)</code> we need the largest <code>ReleaseAtCycle_i - AcquireAtCycle_i</code>&mldr;which is the interval / segment with <strong>longest</strong> length! (i.e. <code>i = P2</code> in this case)</p><p>But let&rsquo;s not stop here: because <code>M = max(ReleaseAtCycles)</code>, the recurring factor becomes&mldr;</p><pre tabindex=0><code>  max(ReleaseAtCycles) - D
= max(ReleaseAtCycles) - M + (ReleaseAtCycle_i - AcquireAtCycle_i), i = P2
= ReleaseAtCycle_i - AcquireAtCycle_i, i = P2</code></pre><p>Which makes the right-most cycle (of all <code>N</code> instructions) we&rsquo;ve been looking for equals to:</p><pre tabindex=0><code>(ReleaseAtCycle_i - AcquireAtCycle_i) x N, i = P2</code></pre><p>As it turns out, the inverse throughput of <code>N</code> instructions with resource segments &ndash; right-most cycle divided by <code>N</code> &ndash; simply equals<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> to the <strong>longest</strong> segment length among all hardware resources!</p><pre tabindex=0><code>Inverse throughput =
  max(ReleaseAtCycle_i - AcquireAtCycle_i), ‚àÄ i = hardware resources</code></pre><p>This formula also covers both the basic cases from section 2 and cases with resource segments.</p><h4 id=discussions>Discussions</h4><p>Here is a little background of why I wrote this post: at the time of writing, <code>MCSchedModel::getReciprocalThroughput</code> doesn&rsquo;t handle <code>AcquireAtCycle</code> at all, this <a href=https://github.com/llvm/llvm-project/pull/130574#discussion_r2005110229>comment</a> from a code review raised a question on how to calculate it, which nerd-sniped me and as a consequence, this post.</p><p>In that thread, <a href=https://github.com/jvillette38>@jvillette38</a> also proposed using longest resource segment as inverse throughput. However, it was slightly counter-intuitive to me at that time as inverse throughput should be calculated from the right-most cycle of all <code>N</code> instructions, yet is the resource with the longest segment <em>always</em> be the one where right-most cycle happens? And in general, what&rsquo;s the connection between the longest segment length and the right-most cycle?</p><p>We&rsquo;ve shown the answer of the first question to be &ldquo;No&rdquo;. Though as it turns out, inverse throughput is still dominated by the longest segment. I think this can partially be explained by <code>D</code>&rsquo;s formula, which suggests that the longest hardware resource segment in the second instruction is always the first to touch its counterpart in the first instruction during left shifting, with <strong>no gap</strong> in between. Implying that the total length (i.e total cycles) is equal or larger than the longest segment length times <code>N</code>. And in the case where resource with the longest segment is not where right-most cycle happens, the &ldquo;delta&rdquo; between the release cycle of <em>last</em> longest segment and the actual right-most cycle will just be a constant which we can happily ignore when <code>N</code> is sufficiently large.</p><p>Anyway, I hope I&rsquo;m not overthinking this whole time üòõ and I hope this post provides a stronger argument on using largest segment length as inverse throughput.</p><h3 id=comments>Comments</h3><p>Feel free to leave comments at <a href=https://github.com/mshockwave/portfolio/discussions/12>https://github.com/mshockwave/portfolio/discussions/12</a></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>This is why metrics like <code>AcquireAtCycle</code> / <code>ReleaseAtCycle</code> sometimes are also called <strong>occupancy</strong> &ndash; the number of cycles it occupies a resource.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>We covered this concept in <a href=/llvm-sched-model-1.5/>here</a>.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Again, assuming number of units in each resource is equal to 1. If it&rsquo;s greater than 1, then the inverse throughput should be further divided by the number of units.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></content><p><a href=/blog/llvm/>#llvm</a>&nbsp;&nbsp;
<a href=/blog/compiler-instruction-scheduling/>#compiler-instruction-scheduling</a>&nbsp;&nbsp;
<a href=/blog/performance/>#performance</a>&nbsp;&nbsp;</p></main><footer><span>¬© 2024 Min-Yih Hsu</span>
<span>|
Made with
<a href=https://github.com/maolonglong/hugo-simple/>Hugo  ï‚Ä¢·¥•‚Ä¢ î Simple</a></span></footer></body></html>